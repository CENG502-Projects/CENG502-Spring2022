{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Report.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP6/Ie5qJapmZ8n+YndMIHc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yesiltepe-hidir/CENG502-Spring2022/blob/main/Report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Paper Information**"
      ],
      "metadata": {
        "id": "WaGHso-Y2fdT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dynamic Inference with Neural Interpreters**"
      ],
      "metadata": {
        "id": "o-zbya4w4wkj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Paper Link:** https://arxiv.org/pdf/2110.06399.pdf\n",
        "* **Authors:** Muhammad Waleed Gondal, Nasim Rahaman, Shruti Joshi, Peter Gehler,\n",
        "Yoshua Bengio, Francesco Locatello, Bernhard Sch√∂lkopf\n",
        "* **Conference:** NeurIPS 2021"
      ],
      "metadata": {
        "id": "eqlApyZL3Miv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Project Group Members**"
      ],
      "metadata": {
        "id": "eo69rIF-4gtu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Alpay √ñzkan, alpay.ozkan@metu.edu.tr\n",
        "* Hƒ±dƒ±r Ye≈üiltepe, hidir.yesiltepe@metu.edu.tr"
      ],
      "metadata": {
        "id": "OHbO5umV5Ayk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Paper Summary** "
      ],
      "metadata": {
        "id": "7GvQ3GbR6lDn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîë This section covers the fundamental ideas & motivation of the paper as well as the proposed architecture."
      ],
      "metadata": {
        "id": "A6LeQG2a7Mqh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Introduction**"
      ],
      "metadata": {
        "id": "L2OI1NDV7ajS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîë Modern neural network architectures are capable of learning the data distribution and generalizes well within the training distribution when large amount of data are supplied. The problem with modern architectures is the lack of interpretation capability: \n",
        "> At the test time model performance is poor when a data which is drawn from related but different distribution is supplied.  \n",
        "\n",
        "This work presents the Neural Interpreter which constitutes a self-attention based network as a system of modules that are called `functions`. Input tokens are fed to model and routed through the `functions` via end to end routing mechanism. Proposed architecture provides capability of computation as an attempt to increase model representation along **depth** and **width**."
      ],
      "metadata": {
        "id": "gSlckAGj7esp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Architecture Overview**\n"
      ],
      "metadata": {
        "id": "Cfxunx0A9Ctp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section covers the backbone architecture along with 7 proposed mechanisms:\n",
        "\n",
        "* ‚èØ Scripts\n",
        "* ‚èØ Functions\n",
        "* ‚èØ Type Matching and Inference\n",
        "* ‚èØ ModLin Layers and ModMLP\n",
        "* ‚èØ ModAttn\n",
        "* ‚èØ Line of Code (LOC)\n",
        "* ‚èØ Interpreter"
      ],
      "metadata": {
        "id": "YGvDPr3qBshu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Input and Output**"
      ],
      "metadata": {
        "id": "MzgxP6QnIgJV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîë Input to the Neural Interpreter is a set of vectors that we denote as $\\{x_i\\}_i$ in which $x_i$ $\\in$ $\\mathbb{R}^{d_{in}}$ and the output is another set of vectors $\\{y_j\\}_j$ where $y_j$ $\\in$ $\\mathbb{R}^{d_{out}}$ with the same cardinality as the input set. Neural Interpreter expects image tokens as input rather than images as in the case of **ViT**. Input set additionally contains the one or more learned class tokens that are called `CLS tokens`. "
      ],
      "metadata": {
        "id": "BKBLwWvNIi1A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src=\"https://cdn-images-1.medium.com/max/800/1*jEhvJTwTViwvUeI3yPvgow.png\"/></center>\n",
        "\n",
        "<p align='center'><b>Figure 1:</b> Neural Interpreter Architecture</p>"
      ],
      "metadata": {
        "id": "vzkN9a5p_TSD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Scripts**"
      ],
      "metadata": {
        "id": "Hb7r-ujw_d9W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîë At the backbone, Neural Interpreter consists of `ns` `Scripts`, in **Figure 1** these scripts are denoted as $Script_1$, $Script_2$ and $Script_3$. Overall, Scripts takes set of vectors of shape `[Batch x N_tokens x Token_dimension]` and maps it into same set cardinality and shape."
      ],
      "metadata": {
        "id": "YSROunD1CoWG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src=\"https://cdn-images-1.medium.com/max/800/1*j1k5I8W9vSlyVIc1nNSThw.png\"/></center>\n",
        "\n",
        "<p align='center'><b>Equation 1:</b>Neural Interpreter stacks scripts ns times to map one input set to another with the same cardinality and shape</p>\n"
      ],
      "metadata": {
        "id": "BSOY6dmbIu_l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "{y<sub>j</sub>}<sub>j</sub> = NeuralInterpreter({x<sub>i</sub>}<sub>i</sub>) = [Script<sub>ns</sub> o ... o (ns times) o Script<sub>1</sub>] ({x<sub>i</sub>}<sub>i</sub>)  "
      ],
      "metadata": {
        "id": "IAoUOhejg_O0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Role:** `Scripts` function as independent building blocks that can be dropped in any set-to-set architecture, and Neural Interpreters with a single script can perform well in practice. "
      ],
      "metadata": {
        "id": "3DNg7ZEvKJRS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Functions**"
      ],
      "metadata": {
        "id": "OT9wzlFPK6-D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîë `Functions` are the unit of computations in the entire architecture meaning that crucial progress happens in this unit. Formally, a `function` can be described with its `code` and `signature` as follow:"
      ],
      "metadata": {
        "id": "5R17XmJ8Lgin"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src=\"https://cdn-images-1.medium.com/max/800/1*5ozH6iir23v8q0dHN8Vyyw.png\"/></center>\n",
        "\n",
        "<p align='center'><b>Equation 2:</b> Function can be described with its code and signature</p>\n",
        "\n"
      ],
      "metadata": {
        "id": "7VA9lPWfL2y7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As denoted in **Equation 2** a `function` (with `function` index `u`) is well defined with two-tuple: (`s`, `u`). Let's dive into the meaning of these symbols."
      ],
      "metadata": {
        "id": "Or6OVTvMPSOa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "~~~ \n",
        "                                                    What are `s` and `c` stands for?\n",
        "~~~"
      ],
      "metadata": {
        "id": "43TjjLlDMu4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Signature` of a `function` is denoted as `s` and have a similar meaning in programming languages. `Signature` is a normalized vector and each  `functions` in the `Script` has its unique `signature`. By means of this distinction among `functions`, in `TypeMatching` mechanism input tokens are routed differently to each `function`.\n",
        "\n",
        "ü•á **Important note:** `Signature` vectors are only shared among function of same types within a script.  "
      ],
      "metadata": {
        "id": "dgo4JOTZQGlO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<center><img src=\"https://cdn-images-1.medium.com/max/800/1*u10hOcOauL5fYnodRzVT8g.png\"/></center>\n",
        "\n",
        "<p align='center'><b>Figure 2:</b> By the help of function signatures, input tokens are distributed independently to the functions</p>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tDkG_sL_Qm6_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Code` of a function is denoted as `c` and it instructs how to process input tokens to the functions. Together with `signature`, it takes role in `TypeMatching` mechanism in order to route input tokens to the functions.\n",
        "\n",
        "ü•á **Important note:** `Code` of a function is shared across same type functions in a script. "
      ],
      "metadata": {
        "id": "yHftodlqQlT9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ü•á **Role:** Functions are vector-valued instructions to other components in\n",
        "the script. They implement the computational units that can be reused in the computational graph."
      ],
      "metadata": {
        "id": "sr2ZOlKIZHvf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Type Matching and Inference**"
      ],
      "metadata": {
        "id": "izqCAKimZsWn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîë Type matching mechanism is at the heart of Neural Interpreters and training stability. If not designed well, mode collapse might occur, meaning that all of the tokens goes only one function or no function takes input (zero-out every token in the mask)."
      ],
      "metadata": {
        "id": "QzAyzaaDZxB0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<center><img src=\"https://cdn-images-1.medium.com/max/800/1*laTgjgiphPqUVhfx49me-Q.png\"/></center>\n",
        "\n",
        "<p align='center'><b>Figure 3:</b> Type Matching Process</p>\n",
        "\n"
      ],
      "metadata": {
        "id": "6AiMpSkMa4W9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Type matching mechanism can be described best as learning proper routing among input tokens and functions. The way routing occurs relies on masking and operates in 3 steps:"
      ],
      "metadata": {
        "id": "nGkl75vYhbd-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.** First, given a set element $x_i$ , it is processed by an MLP module that outputs its type vector $t_i$.\n",
        "\n",
        "**2.** Given a `function` $f_u$ and its `signature` vector\n",
        "$s_u$ ‚àà T , the compatibility $C_{ui}$ between the function fu and a set element $x_i$ is determined by the **cosine similarity** between $s_u$ and $t_i$.\n",
        "\n",
        "**3.** If  compatibility score is larger than a threshold (œÑ), $f_u$ is permitted access to $x_i$\n",
        "."
      ],
      "metadata": {
        "id": "xoZSRuzjbOO9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can describe entire process formally using learnable parameter œÉ and hyperparameter œÑ as the following:"
      ],
      "metadata": {
        "id": "PWP4nDXSgT0f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src=\"https://cdn-images-1.medium.com/max/800/1*UlKTOSTyUuvvjicdh593Ig.png\"/></center>\n",
        "\n",
        "<p align='center'><b>Equation 3:</b> TypeInference yields type vector in space T and distance between signature of the function and type vector is calculated via cosine distance.</p>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7JU31Dz5hrjg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As it can be seen in **Equation 3** type vector $t_i$ is obtained via MLP layer that is called `TypeInference`. Then distance between the signature of the function is calculated by: $d_T(s_u, t_i) = (1 - s_u . t_i)$ "
      ],
      "metadata": {
        "id": "0hna8uF6iUSP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src=\"https://cdn-images-1.medium.com/max/800/1*slym2bo7Fvh1vFk_2-65eg.png\"/></center>\n",
        "\n",
        "<p align='center'><b>Equation 4:</b> Compatiblity score of a token is calculated via negative exponentiation of distance if distance is larger than hyperparameter tau else it is 0. Then Softmax operation is applied to Compatibility scores.</p>\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0r5au7Pjmn-E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîì The compatibility matrix $C_{ui}$ ‚àà [0, 1] will serve as a modulation mask for the self-attention mechanism in the `interpreter`."
      ],
      "metadata": {
        "id": "Z-SYG4xTpbsJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ü•á **Role:** The `TypeMatching` mechanism is responsible for routing\n",
        "information through `functions`. The `truncation parameter` œÑ controls the amount of sparsity in routing."
      ],
      "metadata": {
        "id": "E2Dl-VGfqI1Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ModLin Layers and ModMLP**"
      ],
      "metadata": {
        "id": "HfH4O6Zuqu_F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîë ModLin layer is a Linear layer conditioned on `code` vector. It takes input tokens **x** and `code` vector **c** and performs element-wise fusion operation followed by linear projection as described below:"
      ],
      "metadata": {
        "id": "k0X5h7hIrv0w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src=\"https://cdn-images-1.medium.com/max/800/1*jQVXSvB0tUFgHmrhzC4SNQ.png\"/></center>\n",
        "\n",
        "<p align='center'><b>Equation 5:</b> In ModLin layer, input tokens are element-wise prodcucted with projected code vectors, again projection occurs in demanded dimensional space.</p>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xQGgMAgqsS0G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Further, one may stack the ModLin layers conditioned on the same code vector **c**, which ends up being called **ModMLP**\n"
      ],
      "metadata": {
        "id": "1weC_yvttPpn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src=\"https://cdn-images-1.medium.com/max/800/1*NZids1qWs3MkzcsyJZcOHA.png\"/></center>\n",
        "\n",
        "<p align='center'><b>Equation 6:</b> ModMLP Layer uses ModLin layers + GELU activation function as building blocks.</p>\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qWzUuF_hulvv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ü•á **Role:** `ModLin layers` and the `ModMLP` can be interpreted as programmable\n",
        "neural modules, where the program is specified by the condition or code vector **c**."
      ],
      "metadata": {
        "id": "yShoNMNAFusg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ModAttn**"
      ],
      "metadata": {
        "id": "EqBSPGIAHDUn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîë As discussed before, Neural Interpreter is a self-attention based network. ModAttn is a conditional variant of self attention."
      ],
      "metadata": {
        "id": "RrvixwnYH2t1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<center><img src=\"https://cdn-images-1.medium.com/max/800/1*jamAMvWvSp4FAlQ2L9rySg.png\"/></center>\n",
        "\n",
        "<p align='center'><b>Figure 4:</b> LOC Layer consists of ModAttn and ModMLP Layer</p>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NtT0DhhSI8wP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case, conditional vector is the `function code vector`. Under the light of this, we can deduce **Key**, **Query** and **Value** vectors are as follows:"
      ],
      "metadata": {
        "id": "GfdktAiPJjJc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src=\"https://cdn-images-1.medium.com/max/800/1*2IpsLrgKZLyHcCoHai6D2g.png\"/></center>\n",
        "\n",
        "<p align='center'><b>Equation 7:</b> Computation of Key, Query and Value vectors are conditioned on function code vector.</p>\n",
        "\n"
      ],
      "metadata": {
        "id": "TY-mQIfXLPBi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's make it clear at this point the notation used in **Equation 7**: $k_{uhi}$ means key vector for `function: u` `attention head: h` and calculated via `x: i`, $x_i$. Same notation applies for others."
      ],
      "metadata": {
        "id": "JXcXf06eLmJy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, given the **keys**, **queries** and the function-variable compatibility matrix $C_{ui}$, the modulated self-attention weights $W_{uhij}$ are given by:\n"
      ],
      "metadata": {
        "id": "hkcpWbZnMVmN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src=\"https://cdn-images-1.medium.com/max/800/1*hWuTZPskp1FCfrbgWTlzjA.png\"/></center>\n",
        "\n",
        "<p align='center'><b>Equation 8:</b> Weight calculation for Attention </p>\n",
        "\n"
      ],
      "metadata": {
        "id": "aCWBzbOORWSb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, the quantity $Wuhij$ denotes the attention weights in function $f_u$ between elements $x_i$ and $x_j$\n",
        "at head `h` and the softmax operation normalizes along `j`; intuitively, information about $x_i$ and $x_j$ is\n",
        "mixed by $f_u$ at head h only if $W_{uhij}$ different from 0."
      ],
      "metadata": {
        "id": "RskFFAvURkQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src=\"https://cdn-images-1.medium.com/max/800/1*_DkPT0vUMVLBvZ0h95qHGQ.png\"/></center>\n",
        "\n",
        "<p align='center'><b>Equation 9:</b> Outputs of attention heads are mixed via ModLin </p>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aaGKxRtpTWCq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ü•á **Role:** ModAttn enables interaction between\n",
        "the elements of its input set in multiple parallel streams, one for each function. The query, key, value,\n",
        "and output projectors of each stream are conditioned on the corresponding code vectors, and the\n",
        "interaction between elements in each stream is weighted by their compatibility with the said function."
      ],
      "metadata": {
        "id": "oBzIsYTjUUN-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **LOC Layer**"
      ],
      "metadata": {
        "id": "schZxdvCVFzD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîë An **LOC** layer is a **ModAttn** layer followed by a **ModMLP** layer as shown in **Figure 4**, where both layers share the same condition vector $c_u$, and there are weighted residual\n",
        "connections between the layers. Assuming inputs $\\{x_{ui}\\}_{u,i}$ to the LOC, we have:"
      ],
      "metadata": {
        "id": "yyn1Mq6TVegz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src=\"https://cdn-images-1.medium.com/max/800/1*_PVnHsKEp-gRCB4kIm8OzQ.png\"/></center>\n",
        "\n",
        "<p align='center'><b>Equation 10:</b> Residual connections </p>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qbdLE23zVCW2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ü•á **Role:** Role: A **LOC** can be thought of as multiple instances of a layer in the original transformer architecture\n",
        "(comprising a self-attention and a MLP module with residual connections), applied in parallel streams,\n",
        "one per function. Computations therein are conditioned on the respective code and signature vectors."
      ],
      "metadata": {
        "id": "j44xf9RdWc4s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Interpreter**"
      ],
      "metadata": {
        "id": "jmHV2lFFWrhM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîë The interpreter layer is a stack of `nl` LOCs sharing the same function codes $c_u$ and\n",
        "function-variable compatibilities $C_{ui}$. Assuming the input to the interpreter is a set $\\{x_i\\}_i$, we have:"
      ],
      "metadata": {
        "id": "9IKUJiMKXvj-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src=\"https://cdn-images-1.medium.com/max/800/1*Js3R5ofMmuZjkj5LVeF_2w.png\"/></center>\n",
        "\n",
        "<p align='center'><b>Equation 11:</b> Pooling the output of LOC Layers</p>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PMZV8ZX-X7kr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ü•á **The interpreter** broadcasts a given set element to multiple parallel computational streams,\n",
        "one for each function. After the streams have processed their copy of the input element, the results are\n",
        "aggregated by a weighted sum over the streams, where the weights correspond to the compatibility\n",
        "of the input element with the respective function"
      ],
      "metadata": {
        "id": "EPEmQnhBYNsa"
      }
    }
  ]
}
