{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import warnings\n",
    "from utils.synonyms import SimilarCategories\n",
    "from utils.visual_genome import filter_relationships\n",
    "from utils.visual_genome import get_vg_obj_name\n",
    "from utils.visual_genome import count_relationships\n",
    "from utils.visual_genome import sample_relationships\n",
    "from utils.visualization import view_n_image_rels\n",
    "from utils.visual_genome import extract_obj_categories\n",
    "from utils.primitives import get_primitive_features\n",
    "from utils.primitives import BBoxPrim\n",
    "from utils.visual_genome import get_labels\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from snorkel.labeling import labeling_function\n",
    "from snorkel.labeling import LFApplier\n",
    "from snorkel.labeling.model.label_model import LabelModel\n",
    "from utils.visual_genome import get_vg_obj_name\n",
    "import pickle\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "SEED = 123\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "THRESH = 0.3 # Threshold for rounding the heuristic outputs\n",
    "MIN_SAMPLES_SPLITS = [2, 4, 8, 16, 32, 64, 128] # Number of samples to look at in our decision trees\n",
    "PREDICATE_FILE_PATH = \"data/VisualGenome/orig_pred_list.txt\"\n",
    "\n",
    "def load_dataset(dataset_path):\n",
    "    return np.load(dataset_path)\n",
    "\n",
    "def load_annotations(ann_path):\n",
    "    return json.load(ann_path)\n",
    "\n",
    "def filter_corrupted_images(list1, list2):\n",
    "    return [list1[i] for i in list2]\n",
    "\n",
    "def split_data(annotations, splits):\n",
    "    train = [annotations[i] for i in list(np.where(splits == 0)[0])]\n",
    "    val   = [annotations[i] for i in list(np.where(splits == 1)[0])]\n",
    "    test  = [annotations[i] for i in list(np.where(splits == 2)[0])]\n",
    "    return train, val, test\n",
    "\n",
    "def get_predicates(pred_path):\n",
    "    with open(pred_path, \"r\") as f:\n",
    "        predicates = sorted([x.strip() for x in f.readlines()])\n",
    "    return predicates\n",
    "\n",
    "def get_object_list(object_list_path):\n",
    "    return [x.strip() for x in open(object_list_path, \"r\")]\n",
    "\n",
    "def get_object_synonyms(object_list, synonyms):\n",
    "    object_synonyms = {}\n",
    "    for o in object_list:\n",
    "        object_synonyms[o] = set(synonyms.get_similar_objects([o]) + [o])\n",
    "    return object_synonyms\n",
    "\n",
    "########\n",
    "\n",
    "def fit_heuristic(X_train, Y_train, min_samples_split):\n",
    "    dt = DecisionTreeClassifier(min_samples_split=min_samples_split)\n",
    "    dt.fit(X_train, Y_train)\n",
    "    return dt\n",
    "\n",
    "def prob_to_label(prob_labels, thresh):\n",
    "    # We default all labels to abstains = -1, by Snorkel convention\n",
    "    rounded_labels = np.ones(prob_labels.shape[0]) * -1\n",
    "    for i in range(rounded_labels.shape[0]):\n",
    "        if np.max(prob_labels[i, :]) >= thresh:\n",
    "            # Other classes are labeled as the argmax of estimated probabilities\n",
    "            rounded_labels[i] = np.argmax(prob_labels[i, :])\n",
    "    return rounded_labels\n",
    "\n",
    "def examples_to_feat_matrix(examples: List[any], feature: str):\n",
    "    feature_matrix = []\n",
    "    for x in examples:\n",
    "        feature_matrix.append(getattr(x, feature))\n",
    "    feature_matrix = np.array(feature_matrix)\n",
    "    return feature_matrix\n",
    "\n",
    "def get_lfs(img_agn_features, labeled_mask, multiclass_limited_labels):\n",
    "    lfs = []\n",
    "    for _, ms in enumerate(MIN_SAMPLES_SPLITS):\n",
    "        for feat_key, feat in img_agn_features.items():\n",
    "            heuristic = fit_heuristic(feat[labeled_mask], multiclass_limited_labels, ms)\n",
    "\n",
    "            @labeling_function(\n",
    "                name=f\"heuristic_ms:{ms}_feat:{feat_key}\", \n",
    "                resources=dict(feat_key=feat_key, heuristic=heuristic, thresh=THRESH)\n",
    "            )\n",
    "            def lf(x, feat_key, heuristic, thresh):\n",
    "                feat = getattr(x, feat_key)\n",
    "                feat = np.expand_dims(feat, axis=0)\n",
    "                probs = heuristic.predict_proba(feat)\n",
    "                return prob_to_label(probs, thresh=thresh).squeeze()\n",
    "            lfs.append(lf)\n",
    "    return lfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 108077/108077 [00:02<00:00, 45783.42it/s]\n",
      "100%|██████████| 75651/75651 [00:00<00:00, 111315.47it/s]\n",
      "100%|██████████| 10807/10807 [00:00<00:00, 104909.29it/s]\n",
      "100%|██████████| 21615/21615 [00:00<00:00, 107223.18it/s]\n",
      "100%|██████████| 75651/75651 [00:00<00:00, 331783.66it/s]\n"
     ]
    }
   ],
   "source": [
    "splits = load_dataset(\"data/VisualGenome/split.npy\")\n",
    "valid = load_dataset(\"data/VisualGenome/valid.npy\")\n",
    "annotations = load_annotations(open(\"data/VisualGenome/relationships.json\"))\n",
    "valid_annotations = filter_corrupted_images(annotations, list(valid))\n",
    "train, val, test = split_data(valid_annotations, splits)\n",
    "predicates = get_predicates(PREDICATE_FILE_PATH)\n",
    "object_list = get_object_list(\"data/VisualGenome/object_list.txt\")\n",
    "synonyms = SimilarCategories()\n",
    "all_objects = set(object_list + synonyms.get_similar_objects(object_list))\n",
    "object_filter = lambda r: (get_vg_obj_name(r[\"subject\"]) in all_objects and get_vg_obj_name(r[\"object\"]) in all_objects)\n",
    "filter_relationships(annotations, object_filter, inplace=True)\n",
    "predicate_filter = lambda r: r[\"predicate\"].lower() in predicates\n",
    "filtered_train = filter_relationships(train, predicate_filter)\n",
    "filtered_val = filter_relationships(val, predicate_filter)\n",
    "filtered_test = filter_relationships(test, predicate_filter)\n",
    "train_counts = count_relationships(filtered_train)\n",
    "cardinality = len(predicates)\n",
    "LIMITED_LABEL_TRAIN = sample_relationships(filtered_train, train_counts, n_per_pred=10)\n",
    "# view_n_image_rels(LIMITED_LABEL_TRAIN, n=3)\n",
    "object_synonyms = get_object_synonyms(object_list, synonyms)\n",
    "obj_categories = extract_obj_categories(annotations, predicates, object_synonyms)\n",
    "limited_labels = get_labels(LIMITED_LABEL_TRAIN, predicates)\n",
    "EVAL_VALID = filtered_val # Used to validate performance of our training labels, hyperparameters, etc.\n",
    "# ORACLE_TRAIN = filtered_train # Includes ALL labels\n",
    "EVAL_TEST = filtered_test # Used to evaluate the downstream scene graph model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_of_label(relation):\n",
    "    for pred in predicates:\n",
    "        if pred == relation:\n",
    "            return predicates.index(relation)\n",
    "\n",
    "index_of_wear = get_index_of_label(\"wearing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75651/75651 [00:01<00:00, 42965.20it/s]\n",
      "100%|██████████| 75651/75651 [00:00<00:00, 334629.05it/s]\n",
      "70978it [01:03, 1118.38it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_primitives_labels():\n",
    "    train_examples = get_primitive_features(LIMITED_LABEL_TRAIN, obj_categories, object_synonyms)\n",
    "    limited_labels = get_labels(LIMITED_LABEL_TRAIN, predicates)\n",
    "    np.unique(limited_labels)\n",
    "    unlabeled_mask = np.sum(limited_labels, axis=1) == len(predicates) * -1\n",
    "    labeled_mask = np.logical_not(unlabeled_mask)\n",
    "    assert np.sum(labeled_mask) + np.sum(unlabeled_mask) == len(limited_labels)\n",
    "    multiclass_limited_labels = np.where(limited_labels[labeled_mask, :] == 1.0)[1]\n",
    "    img_agn_features = {\n",
    "        \"spatial\": examples_to_feat_matrix(train_examples, feature=\"spatial\"),\n",
    "        \"categorical\": examples_to_feat_matrix(train_examples, feature=\"categorical\")}\n",
    "    lfs = get_lfs(img_agn_features, labeled_mask, multiclass_limited_labels)\n",
    "    applier = LFApplier(lfs)\n",
    "    L_train = applier.apply(train_examples)\n",
    "    return L_train, applier, lfs\n",
    "\n",
    "L_train_paper, applier_paper, lfs_paper = get_primitives_labels()\n",
    "with open('./lf1234678/L_train_paper.pickle', 'wb') as f:\n",
    "    pickle.dump(L_train_paper, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "my_lfs = []\n",
    "@labeling_function(name=\"my_lf1\")\n",
    "def my_lf1(x):\n",
    "    if x[0].area > x[1].area:\n",
    "        return index_of_wear\n",
    "    else:\n",
    "        return -1\n",
    "my_lfs.append(my_lf1)\n",
    "@labeling_function(name=\"my_lf2\")\n",
    "def my_lf2(x):\n",
    "    clothes = [\"shirt\", \"t-shirt\", \"pullover\", \"sweatshirt\", \"hoodie\",\n",
    "               \"dress\", \"skirt\", \"jean\", \"short\", \"pyjama\", \"pants\",\n",
    "               \"suit\",  \"blouse\", \"jacket\", \"glove\", \"swimsuit\", \"bikini\",\n",
    "               \"shoe\", \"sandal\", \"boot\", \"slipper\", \"sock\", \"hat\", \"cap\",\n",
    "               \"glasses\", \"scarf\", \"sunglasses\", \"watch\", \"belt\"]\n",
    "    if x[3] in clothes:\n",
    "        return index_of_wear\n",
    "    else:\n",
    "        return -1\n",
    "my_lfs.append(my_lf2)\n",
    "@labeling_function(name=\"my_lf3\")\n",
    "def my_lf3(x):\n",
    "    clothes = [\"hat\", \"cap\"]\n",
    "    middle_point_of_subject = x[0].x0 + int(x[0].height/2)\n",
    "    if x[3] in clothes and x[1].x0 < middle_point_of_subject:\n",
    "        return index_of_wear\n",
    "    else:\n",
    "        return -1\n",
    "my_lfs.append(my_lf3)\n",
    "@labeling_function(name=\"my_lf4\")\n",
    "def my_lf4(x):\n",
    "    clothes = [\"skirt\", \"jean\", \"short\", \"pants\"]\n",
    "    middle_point_of_subject = x[0].x0 + int(x[0].height/2)\n",
    "    if x[3] in clothes and x[1].x0 > middle_point_of_subject:\n",
    "        return index_of_wear\n",
    "    else:\n",
    "        return -1\n",
    "my_lfs.append(my_lf4)\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "\n",
    "@labeling_function(name=\"my_lf6\")\n",
    "def my_lf6(x):\n",
    "    text = f\"[SEP] {x[2]} [MASK] {x[3]}\"\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    masked_index = tokenized_text.index(\"[MASK]\")\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor)\n",
    "        predictions = outputs[0]\n",
    "    probs = torch.nn.functional.softmax(predictions[0, masked_index], dim=-1)\n",
    "    _, top_fifty_indices = torch.topk(probs, 50, sorted=True)\n",
    "    for pred_idx in top_fifty_indices:\n",
    "        predicted_token = tokenizer.convert_ids_to_tokens([pred_idx])[0]\n",
    "        if predicted_token in predicates:\n",
    "            return predicates.index(predicted_token)\n",
    "    return -1\n",
    "my_lfs.append(my_lf6)\n",
    "\n",
    "@labeling_function(name=\"my_lf7\")\n",
    "def my_lf7(x):\n",
    "    text = f\"[SEP] {x[2]} and {x[3]} are [MASK]\"\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    masked_index = tokenized_text.index(\"[MASK]\")\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor)\n",
    "        predictions = outputs[0]\n",
    "    probs = torch.nn.functional.softmax(predictions[0, masked_index], dim=-1)\n",
    "    _, top_fifty_indices = torch.topk(probs, 50, sorted=True)\n",
    "    for pred_idx in top_fifty_indices:\n",
    "        predicted_token = tokenizer.convert_ids_to_tokens([pred_idx])[0]\n",
    "        if predicted_token in predicates:\n",
    "            return predicates.index(predicted_token)\n",
    "    return -1\n",
    "my_lfs.append(my_lf7)\n",
    "\n",
    "@labeling_function(name=\"my_lf8\")\n",
    "def my_lf8(x):\n",
    "    text = f\"[SEP] {x[2]} is [MASK] {x[3]}\"\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    masked_index = tokenized_text.index(\"[MASK]\")\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor)\n",
    "        predictions = outputs[0]\n",
    "    probs = torch.nn.functional.softmax(predictions[0, masked_index], dim=-1)\n",
    "    _, top_fifty_indices = torch.topk(probs, 50, sorted=True)\n",
    "    for pred_idx in top_fifty_indices:\n",
    "        predicted_token = tokenizer.convert_ids_to_tokens([pred_idx])[0]\n",
    "        if predicted_token in predicates:\n",
    "            return predicates.index(predicted_token)\n",
    "    return -1\n",
    "my_lfs.append(my_lf8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "70978it [1:56:11, 10.18it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_my_train_examples(train_examples):\n",
    "    examples = []\n",
    "    for a in train_examples:\n",
    "        for r in a[\"relationships\"]:\n",
    "            sub_bbox = BBoxPrim.from_vg_obj(r[\"subject\"])\n",
    "            obj_bbox = BBoxPrim.from_vg_obj(r[\"object\"])\n",
    "            sub_name = get_vg_obj_name(r[\"subject\"])\n",
    "            obj_name = get_vg_obj_name(r[\"object\"])\n",
    "            image_id = a[\"image_id\"]\n",
    "            x = (sub_bbox, obj_bbox, sub_name, obj_name, image_id)\n",
    "            examples.append(x)\n",
    "    return examples\n",
    "\n",
    "train_examples = get_my_train_examples(LIMITED_LABEL_TRAIN)\n",
    "with open('./lf1234678/train_examples.pickle', 'wb') as f:\n",
    "    pickle.dump(train_examples, f)\n",
    "my_applier = LFApplier(my_lfs)\n",
    "my_L_train = my_applier.apply(train_examples)\n",
    "with open('./lf1234678/my_L_train.pickle', 'wb') as f:\n",
    "    pickle.dump(my_L_train, f)\n",
    "L_train_main = np.concatenate((L_train_paper, my_L_train), axis=1)\n",
    "with open('./lf1234678/L_train_main.pickle', 'wb') as f:\n",
    "    pickle.dump(L_train_main, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('says', 6), ('playing', 7), ('flying in', 11), ('walking in', 16), ('lying on', 48), ('covered in', 51), ('painted on', 59), ('covering', 62), ('hanging from', 64), ('using', 77), ('mounted on', 84), ('parked on', 98), ('eating', 107), ('watching', 114), ('growing on', 122), ('walking on', 204), ('carrying', 205), ('standing on', 341), ('riding', 457), ('sitting on', 565), ('wearing', 6412), ('_TOTAL', 9110)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10807/10807 [00:00<00:00, 675073.99it/s]\n"
     ]
    }
   ],
   "source": [
    "val_counts = count_relationships(filtered_val)\n",
    "print(sorted(val_counts.items(), key=lambda x:x[1]))\n",
    "class_balance = np.array([val_counts[k] / val_counts[\"_TOTAL\"] for k in sorted(predicates)])\n",
    "N_EPOCHS = 60\n",
    "valid_labels = get_labels(EVAL_VALID, predicates)\n",
    "multiclass_labels_valid = np.where(valid_labels == 1.0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/60 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=7.136]\n",
      "INFO:root:[10 epochs]: TRAIN:[loss=2.472]\n",
      "INFO:root:[20 epochs]: TRAIN:[loss=2.550]\n",
      " 45%|████▌     | 27/60 [00:00<00:00, 267.31epoch/s]INFO:root:[30 epochs]: TRAIN:[loss=2.319]\n",
      "INFO:root:[40 epochs]: TRAIN:[loss=2.180]\n",
      "INFO:root:[50 epochs]: TRAIN:[loss=2.118]\n",
      "100%|██████████| 60/60 [00:00<00:00, 312.50epoch/s]\n",
      "INFO:root:Finished Training\n",
      "100%|██████████| 10807/10807 [00:00<00:00, 40431.94it/s]\n",
      "9110it [00:08, 1076.22it/s]\n",
      "100%|██████████| 10807/10807 [00:00<00:00, 720576.16it/s]\n",
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8073545554335895}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_model_paper = LabelModel(cardinality=cardinality, verbose=True)\n",
    "label_model_paper.fit(L_train_paper, class_balance=class_balance, seed=SEED, lr=0.01, l2=0.01, log_freq=10, n_epochs=N_EPOCHS)\n",
    "with open('./lf1234678/label_model_paper.pickle', 'wb') as f:\n",
    "    pickle.dump(label_model_paper, f)\n",
    "\n",
    "weak_labels = label_model_paper.predict_proba(L_train_paper)\n",
    "valid_examples = get_primitive_features(EVAL_VALID, obj_categories, object_synonyms)\n",
    "L_valid_paper = applier_paper.apply(valid_examples)\n",
    "with open('./lf1234678/L_valid_paper.pickle', 'wb') as f:\n",
    "    pickle.dump(L_valid_paper, f)\n",
    "\n",
    "valid_labels = get_labels(EVAL_VALID, predicates)\n",
    "multiclass_labels_valid = np.where(valid_labels == 1.0)[1]\n",
    "label_model_paper.score(L_valid_paper, multiclass_labels_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/60 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=2.370]\n",
      "INFO:root:[10 epochs]: TRAIN:[loss=0.665]\n",
      "INFO:root:[20 epochs]: TRAIN:[loss=0.306]\n",
      "INFO:root:[30 epochs]: TRAIN:[loss=0.118]\n",
      "INFO:root:[40 epochs]: TRAIN:[loss=0.059]\n",
      "INFO:root:[50 epochs]: TRAIN:[loss=0.033]\n",
      "100%|██████████| 60/60 [00:00<00:00, 1132.02epoch/s]\n",
      "INFO:root:Finished Training\n",
      "9110it [14:28, 10.49it/s]\n",
      "100%|██████████| 10807/10807 [00:00<00:00, 720072.49it/s]\n",
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7327113062568605}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_model_my = LabelModel(cardinality=cardinality, verbose=True)\n",
    "label_model_my.fit(my_L_train, class_balance=class_balance, seed=SEED, lr=0.01, l2=0.01, log_freq=10, n_epochs=N_EPOCHS)\n",
    "with open('./lf1234678/label_model_my.pickle', 'wb') as f:\n",
    "    pickle.dump(label_model_my, f)\n",
    "    \n",
    "weak_labels = label_model_my.predict_proba(my_L_train)\n",
    "my_valid_examples = get_my_train_examples(EVAL_VALID)\n",
    "with open('./lf1234678/my_valid_examples.pickle', 'wb') as f:\n",
    "    pickle.dump(my_valid_examples, f)\n",
    "\n",
    "my_L_valid = my_applier.apply(my_valid_examples)\n",
    "with open('./lf1234678/my_L_valid.pickle', 'wb') as f:\n",
    "    pickle.dump(my_L_valid, f)\n",
    "\n",
    "valid_labels = get_labels(EVAL_VALID, predicates)\n",
    "multiclass_labels_valid = np.where(valid_labels == 1.0)[1]\n",
    "label_model_my.score(my_L_valid, multiclass_labels_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/60 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=16.942]\n",
      "INFO:root:[10 epochs]: TRAIN:[loss=3.825]\n",
      "INFO:root:[20 epochs]: TRAIN:[loss=3.217]\n",
      " 47%|████▋     | 28/60 [00:00<00:00, 276.56epoch/s]INFO:root:[30 epochs]: TRAIN:[loss=2.548]\n",
      "INFO:root:[40 epochs]: TRAIN:[loss=2.503]\n",
      "INFO:root:[50 epochs]: TRAIN:[loss=2.266]\n",
      "100%|██████████| 60/60 [00:00<00:00, 276.15epoch/s]\n",
      "INFO:root:Finished Training\n",
      "100%|██████████| 10807/10807 [00:00<00:00, 41724.94it/s]\n",
      "9110it [00:08, 1086.08it/s]\n",
      "9110it [14:34, 10.42it/s]\n",
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8159165751920966}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_model_main = LabelModel(cardinality=cardinality, verbose=True)\n",
    "label_model_main.fit(L_train_main, class_balance=class_balance, seed=SEED, lr=0.01, l2=0.01, log_freq=10, n_epochs=N_EPOCHS)\n",
    "with open('./lf1234678/label_model_main.pickle', 'wb') as f:\n",
    "    pickle.dump(label_model_main, f)\n",
    "weak_labels_main = label_model_main.predict_proba(L_train_main)\n",
    "\n",
    "valid_examples_paper = get_primitive_features(EVAL_VALID, obj_categories, object_synonyms)\n",
    "L_valid_paper = applier_paper.apply(valid_examples_paper)\n",
    "\n",
    "my_valid_examples = get_my_train_examples(EVAL_VALID)\n",
    "my_L_valid = my_applier.apply(my_valid_examples)\n",
    "\n",
    "L_valid_main = np.concatenate((L_valid_paper, my_L_valid), axis=1)\n",
    "with open('./lf1234678/L_valid_main.pickle', 'wb') as f:\n",
    "    pickle.dump(L_valid_main, f)\n",
    "label_model_main.score(L_valid_main, multiclass_labels_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>heuristic_ms:2_feat:spatial</th>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989023</td>\n",
       "      <td>2690</td>\n",
       "      <td>6420</td>\n",
       "      <td>0.295280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heuristic_ms:2_feat:categorical</th>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989023</td>\n",
       "      <td>3631</td>\n",
       "      <td>5479</td>\n",
       "      <td>0.398573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heuristic_ms:4_feat:spatial</th>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989023</td>\n",
       "      <td>1876</td>\n",
       "      <td>7234</td>\n",
       "      <td>0.205928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heuristic_ms:4_feat:categorical</th>\n",
       "      <td>3</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989023</td>\n",
       "      <td>3602</td>\n",
       "      <td>5508</td>\n",
       "      <td>0.395390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heuristic_ms:8_feat:spatial</th>\n",
       "      <td>4</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>0.781778</td>\n",
       "      <td>0.781778</td>\n",
       "      <td>0.771021</td>\n",
       "      <td>1540</td>\n",
       "      <td>5582</td>\n",
       "      <td>0.216231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heuristic_ms:8_feat:categorical</th>\n",
       "      <td>5</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989023</td>\n",
       "      <td>3267</td>\n",
       "      <td>5843</td>\n",
       "      <td>0.358617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heuristic_ms:16_feat:spatial</th>\n",
       "      <td>6</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15...</td>\n",
       "      <td>0.835565</td>\n",
       "      <td>0.835565</td>\n",
       "      <td>0.825576</td>\n",
       "      <td>3227</td>\n",
       "      <td>4385</td>\n",
       "      <td>0.423936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heuristic_ms:16_feat:categorical</th>\n",
       "      <td>7</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>0.722942</td>\n",
       "      <td>0.722942</td>\n",
       "      <td>0.712075</td>\n",
       "      <td>3204</td>\n",
       "      <td>3382</td>\n",
       "      <td>0.486486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heuristic_ms:32_feat:spatial</th>\n",
       "      <td>8</td>\n",
       "      <td>[0, 3, 4, 5, 6, 8, 12, 14, 15, 16]</td>\n",
       "      <td>0.871240</td>\n",
       "      <td>0.871240</td>\n",
       "      <td>0.862569</td>\n",
       "      <td>452</td>\n",
       "      <td>7485</td>\n",
       "      <td>0.056948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heuristic_ms:32_feat:categorical</th>\n",
       "      <td>9</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>0.376290</td>\n",
       "      <td>0.376290</td>\n",
       "      <td>0.365642</td>\n",
       "      <td>2690</td>\n",
       "      <td>738</td>\n",
       "      <td>0.784714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heuristic_ms:64_feat:spatial</th>\n",
       "      <td>10</td>\n",
       "      <td>[4]</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heuristic_ms:64_feat:categorical</th>\n",
       "      <td>11</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 14, 1...</td>\n",
       "      <td>0.335785</td>\n",
       "      <td>0.335785</td>\n",
       "      <td>0.326125</td>\n",
       "      <td>2503</td>\n",
       "      <td>556</td>\n",
       "      <td>0.818241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heuristic_ms:128_feat:spatial</th>\n",
       "      <td>12</td>\n",
       "      <td>[4]</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heuristic_ms:128_feat:categorical</th>\n",
       "      <td>13</td>\n",
       "      <td>[1, 2, 4, 5, 9, 10, 13, 18]</td>\n",
       "      <td>0.070033</td>\n",
       "      <td>0.070033</td>\n",
       "      <td>0.064874</td>\n",
       "      <td>350</td>\n",
       "      <td>288</td>\n",
       "      <td>0.548589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my_lf1</th>\n",
       "      <td>14</td>\n",
       "      <td>[20]</td>\n",
       "      <td>0.796597</td>\n",
       "      <td>0.796597</td>\n",
       "      <td>0.796597</td>\n",
       "      <td>6296</td>\n",
       "      <td>961</td>\n",
       "      <td>0.867576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my_lf2</th>\n",
       "      <td>15</td>\n",
       "      <td>[20]</td>\n",
       "      <td>0.475631</td>\n",
       "      <td>0.475631</td>\n",
       "      <td>0.475631</td>\n",
       "      <td>4327</td>\n",
       "      <td>6</td>\n",
       "      <td>0.998615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my_lf3</th>\n",
       "      <td>16</td>\n",
       "      <td>[20]</td>\n",
       "      <td>0.070252</td>\n",
       "      <td>0.070252</td>\n",
       "      <td>0.070252</td>\n",
       "      <td>639</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my_lf4</th>\n",
       "      <td>17</td>\n",
       "      <td>[20]</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my_lf6</th>\n",
       "      <td>18</td>\n",
       "      <td>[0, 2, 3, 11, 12, 13, 16, 19, 20]</td>\n",
       "      <td>0.722173</td>\n",
       "      <td>0.722173</td>\n",
       "      <td>0.718332</td>\n",
       "      <td>5805</td>\n",
       "      <td>774</td>\n",
       "      <td>0.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my_lf7</th>\n",
       "      <td>19</td>\n",
       "      <td>[3, 11, 12, 20]</td>\n",
       "      <td>0.036334</td>\n",
       "      <td>0.036334</td>\n",
       "      <td>0.036334</td>\n",
       "      <td>200</td>\n",
       "      <td>131</td>\n",
       "      <td>0.604230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my_lf8</th>\n",
       "      <td>20</td>\n",
       "      <td>[0, 2, 3, 11, 12, 16, 19, 20]</td>\n",
       "      <td>0.802415</td>\n",
       "      <td>0.802415</td>\n",
       "      <td>0.801098</td>\n",
       "      <td>6190</td>\n",
       "      <td>1120</td>\n",
       "      <td>0.846785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    j  \\\n",
       "heuristic_ms:2_feat:spatial         0   \n",
       "heuristic_ms:2_feat:categorical     1   \n",
       "heuristic_ms:4_feat:spatial         2   \n",
       "heuristic_ms:4_feat:categorical     3   \n",
       "heuristic_ms:8_feat:spatial         4   \n",
       "heuristic_ms:8_feat:categorical     5   \n",
       "heuristic_ms:16_feat:spatial        6   \n",
       "heuristic_ms:16_feat:categorical    7   \n",
       "heuristic_ms:32_feat:spatial        8   \n",
       "heuristic_ms:32_feat:categorical    9   \n",
       "heuristic_ms:64_feat:spatial       10   \n",
       "heuristic_ms:64_feat:categorical   11   \n",
       "heuristic_ms:128_feat:spatial      12   \n",
       "heuristic_ms:128_feat:categorical  13   \n",
       "my_lf1                             14   \n",
       "my_lf2                             15   \n",
       "my_lf3                             16   \n",
       "my_lf4                             17   \n",
       "my_lf6                             18   \n",
       "my_lf7                             19   \n",
       "my_lf8                             20   \n",
       "\n",
       "                                                                            Polarity  \\\n",
       "heuristic_ms:2_feat:spatial        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "heuristic_ms:2_feat:categorical    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "heuristic_ms:4_feat:spatial        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "heuristic_ms:4_feat:categorical    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "heuristic_ms:8_feat:spatial        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "heuristic_ms:8_feat:categorical    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "heuristic_ms:16_feat:spatial       [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15...   \n",
       "heuristic_ms:16_feat:categorical   [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "heuristic_ms:32_feat:spatial                      [0, 3, 4, 5, 6, 8, 12, 14, 15, 16]   \n",
       "heuristic_ms:32_feat:categorical   [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "heuristic_ms:64_feat:spatial                                                     [4]   \n",
       "heuristic_ms:64_feat:categorical   [0, 1, 2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 14, 1...   \n",
       "heuristic_ms:128_feat:spatial                                                    [4]   \n",
       "heuristic_ms:128_feat:categorical                        [1, 2, 4, 5, 9, 10, 13, 18]   \n",
       "my_lf1                                                                          [20]   \n",
       "my_lf2                                                                          [20]   \n",
       "my_lf3                                                                          [20]   \n",
       "my_lf4                                                                          [20]   \n",
       "my_lf6                                             [0, 2, 3, 11, 12, 13, 16, 19, 20]   \n",
       "my_lf7                                                               [3, 11, 12, 20]   \n",
       "my_lf8                                                 [0, 2, 3, 11, 12, 16, 19, 20]   \n",
       "\n",
       "                                   Coverage  Overlaps  Conflicts  Correct  \\\n",
       "heuristic_ms:2_feat:spatial        1.000000  1.000000   0.989023     2690   \n",
       "heuristic_ms:2_feat:categorical    1.000000  1.000000   0.989023     3631   \n",
       "heuristic_ms:4_feat:spatial        1.000000  1.000000   0.989023     1876   \n",
       "heuristic_ms:4_feat:categorical    1.000000  1.000000   0.989023     3602   \n",
       "heuristic_ms:8_feat:spatial        0.781778  0.781778   0.771021     1540   \n",
       "heuristic_ms:8_feat:categorical    1.000000  1.000000   0.989023     3267   \n",
       "heuristic_ms:16_feat:spatial       0.835565  0.835565   0.825576     3227   \n",
       "heuristic_ms:16_feat:categorical   0.722942  0.722942   0.712075     3204   \n",
       "heuristic_ms:32_feat:spatial       0.871240  0.871240   0.862569      452   \n",
       "heuristic_ms:32_feat:categorical   0.376290  0.376290   0.365642     2690   \n",
       "heuristic_ms:64_feat:spatial       0.000549  0.000549   0.000549        0   \n",
       "heuristic_ms:64_feat:categorical   0.335785  0.335785   0.326125     2503   \n",
       "heuristic_ms:128_feat:spatial      0.000549  0.000549   0.000549        0   \n",
       "heuristic_ms:128_feat:categorical  0.070033  0.070033   0.064874      350   \n",
       "my_lf1                             0.796597  0.796597   0.796597     6296   \n",
       "my_lf2                             0.475631  0.475631   0.475631     4327   \n",
       "my_lf3                             0.070252  0.070252   0.070252      639   \n",
       "my_lf4                             0.000988  0.000988   0.000988        9   \n",
       "my_lf6                             0.722173  0.722173   0.718332     5805   \n",
       "my_lf7                             0.036334  0.036334   0.036334      200   \n",
       "my_lf8                             0.802415  0.802415   0.801098     6190   \n",
       "\n",
       "                                   Incorrect  Emp. Acc.  \n",
       "heuristic_ms:2_feat:spatial             6420   0.295280  \n",
       "heuristic_ms:2_feat:categorical         5479   0.398573  \n",
       "heuristic_ms:4_feat:spatial             7234   0.205928  \n",
       "heuristic_ms:4_feat:categorical         5508   0.395390  \n",
       "heuristic_ms:8_feat:spatial             5582   0.216231  \n",
       "heuristic_ms:8_feat:categorical         5843   0.358617  \n",
       "heuristic_ms:16_feat:spatial            4385   0.423936  \n",
       "heuristic_ms:16_feat:categorical        3382   0.486486  \n",
       "heuristic_ms:32_feat:spatial            7485   0.056948  \n",
       "heuristic_ms:32_feat:categorical         738   0.784714  \n",
       "heuristic_ms:64_feat:spatial               5   0.000000  \n",
       "heuristic_ms:64_feat:categorical         556   0.818241  \n",
       "heuristic_ms:128_feat:spatial              5   0.000000  \n",
       "heuristic_ms:128_feat:categorical        288   0.548589  \n",
       "my_lf1                                   961   0.867576  \n",
       "my_lf2                                     6   0.998615  \n",
       "my_lf3                                     1   0.998437  \n",
       "my_lf4                                     0   1.000000  \n",
       "my_lf6                                   774   0.882353  \n",
       "my_lf7                                   131   0.604230  \n",
       "my_lf8                                  1120   0.846785  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.labeling import LFAnalysis\n",
    "lfs = lfs_paper + my_lfs\n",
    "LFAnalysis(L_valid_main, lfs).lf_summary(multiclass_labels_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
